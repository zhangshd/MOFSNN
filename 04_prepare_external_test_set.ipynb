{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws4_set_dir = \"./raw_data/WS24v2/data_sets/validation_set\"\n",
    "tsd_ssd_dir = \"./raw_data/Nandy_2022_SciData/blinded_test_set\"\n",
    "tgt_root_dir = \"./CGCNN_MT/data\"\n",
    "core_mof_dir = Path(\"./raw_data/CoRE2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_ws_dir = Path(tgt_root_dir)/\"WS24v2_external_test\"\n",
    "tgt_ts_dir = Path(tgt_root_dir)/\"TS_external_test\"\n",
    "\n",
    "# create directories\n",
    "tgt_ws_dir.mkdir(parents=True, exist_ok=True)\n",
    "tgt_ts_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_label_file = Path(ws4_set_dir)/\"sources_labels_v2.csv\"\n",
    "ts_label_file = Path(tsd_ssd_dir)/\"blinded_40_elsevier_MOFs.csv\"\n",
    "\n",
    "df_ws = pd.read_csv(ws_label_file)\n",
    "df_ts = pd.read_csv(ts_label_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The prediction performance of the external test set in source reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solvent removal stability accuracy: 0.775\n",
      "Solvent removal stability AUC: 0.8800000000000001\n",
      "Thermal stability R^2: 0.3144906985649343\n",
      "Thermal stability MAE: 54.582698990000004\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "df_ts.head()\n",
    "ss_acc = metrics.accuracy_score(df_ts['label (solvent removal stability)'], df_ts['predicted label (solvent removal stability)'])\n",
    "ss_auc = metrics.roc_auc_score(df_ts['label (solvent removal stability)'], df_ts['predicted probability (solvent removal stability)'])\n",
    "ts_r2= metrics.r2_score(df_ts['label (thermal stability)'], df_ts['predicted Td (thermal stability)'])\n",
    "ts_mae = metrics.mean_absolute_error(df_ts['label (thermal stability)'], df_ts['predicted Td (thermal stability)'])\n",
    "\n",
    "print('Solvent removal stability accuracy:', ss_acc)\n",
    "print('Solvent removal stability AUC:', ss_auc)\n",
    "print('Thermal stability R^2:', ts_r2)\n",
    "print('Thermal stability MAE:', ts_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prepare external test set for water stability\n",
    "df_ws.rename({\n",
    "    'water_stability_label': 'water4_label',\n",
    "    'file_name': 'MofName'\n",
    "\n",
    "}, axis=1, inplace=True)\n",
    "\n",
    "df_ws[\"water_label\"] = df_ws[\"water4_label\"].apply(lambda x: 1 if x >2 else 0)\n",
    "df_ws[\"water4_label\"] = df_ws[\"water4_label\"]\n",
    "df_ws[\"MofName\"] = df_ws[\"MofName\"].apply(lambda x: x.split('.')[0])\n",
    "\n",
    "valid_cols = ['MofName', 'MOF_name', \"CCDC_refcode\", 'water_label', 'water4_label', 'acid_label', 'base_label', 'boiling_label']\n",
    "df_ws = df_ws[valid_cols]\n",
    "\n",
    "df_ws.insert(1, \"Partition\", \"external_test\")\n",
    "\n",
    "\n",
    "### Copy CIF files to external test set directory\n",
    "tgt_ws_cif_dir = tgt_ws_dir/'cifs'\n",
    "tgt_ws_cif_dir.mkdir(exist_ok=True)\n",
    "failed_mofs = []\n",
    "for cifid in df_ws['MofName']:\n",
    "    cif_file = Path(ws4_set_dir)/f\"CIFs/{cifid}.cif\"\n",
    "    if not cif_file.exists():\n",
    "        failed_mofs.append(cifid)\n",
    "        continue\n",
    "    shutil.copy(str(cif_file), tgt_ws_cif_dir)\n",
    "df_ws = df_ws[~df_ws['MofName'].isin(failed_mofs)]\n",
    "df_ws.to_csv(tgt_ws_dir/'id_prop.csv', index=False)\n",
    "\n",
    "##  Prepare external test set for thermal stability and solvent removal stability\n",
    "df_ts.rename({\n",
    "    'label (solvent removal stability)': 'ss_label',\n",
    "    'label (thermal stability)': 'ts_label',\n",
    "    'CoRE_name': 'MofName'\n",
    "\n",
    "}, axis=1, inplace=True)\n",
    "\n",
    "valid_cols = ['MofName', \"refcode\", 'ts_label', 'ss_label']\n",
    "df_ts = df_ts[valid_cols]\n",
    "df_ts.insert(1, \"Partition\", \"external_test\")\n",
    "df_ts.to_csv(tgt_ts_dir/'id_prop.csv', index=False)\n",
    "\n",
    "### Copy CIF files to external test set directory\n",
    "tgt_ts_cif_dir = tgt_ts_dir/'cifs'\n",
    "tgt_ts_cif_dir.mkdir(exist_ok=True)\n",
    "for cifid in df_ts['CifId']:\n",
    "    cif_file = Path(core_mof_dir)/f\"{cifid}.cif\"\n",
    "    # shutil.copy(str(cif_file), tgt_ts_cif_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean cifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "def run_slurm_job(work_dir, executor=\"sbatch\", script_name=\"run\"):\n",
    "    work_dir = Path(work_dir)\n",
    "    process = subprocess.Popen(\n",
    "        f\"{executor} {work_dir/script_name}\",\n",
    "        # [executor, str(work_dir/'run'), \"&\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        shell=True,\n",
    "        env=os.environ.copy(),\n",
    "        cwd=str(work_dir)\n",
    "    )\n",
    "    return process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 199515\n",
      "Submitted job clean_WS24v2_external_test with PID 2140453\n"
     ]
    }
   ],
   "source": [
    "job_templet = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --output={log_dir}/%x_%A.out\n",
    "#SBATCH --error={log_dir}/%x_%A.err\n",
    "#SBATCH --partition=C9654 \n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task={n_cpus}\n",
    "#SBATCH --mem-per-cpu=50G\n",
    "\n",
    "export PATH=/opt/share/miniconda3/envs/mofmthnn/bin/:$PATH\n",
    "export LD_LIBRARY_PATH=/opt/share/miniconda3/envs/mofmthnn/lib/:$LD_LIBRARY_PATH\n",
    "\n",
    "srun python -u clean_cif.py --cif_dir {cif_dir} --output_dir {output_dir} --santize {santize} --log_file {log_file} --n_cpus {n_cpus}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "script_name = \"clean.sh\"\n",
    "work_dir = Path(\"./CGCNN_MT/datamodule\")\n",
    "\n",
    "cif_dirs = [\n",
    "    # \"./CGCNN_MT/data/TS_external_test/cifs\",\n",
    "    \"./CGCNN_MT/data/WS24v2_external_test/cifs\"\n",
    "]\n",
    "\n",
    "for cif_dir in cif_dirs:\n",
    "    job_name = f\"clean_{Path(cif_dir).parent.name}\"\n",
    "    n_cpus = 1\n",
    "    santize = False\n",
    "    output_dir = Path(cif_dir).parent / \"clean_cifs\"\n",
    "    log_dir = Path(cif_dir).parent\n",
    "    if output_dir.exists():\n",
    "        shutil.rmtree(output_dir)\n",
    "    log_file = output_dir / \"clean.log\"\n",
    "    job_script = job_templet.format(job_name=job_name, \n",
    "                                            cif_dir=cif_dir, \n",
    "                                            output_dir=output_dir,\n",
    "                                            log_file=log_file,\n",
    "                                            n_cpus=n_cpus,\n",
    "                                            santize=santize,\n",
    "                                            log_dir=log_dir\n",
    "                                            )\n",
    "    with open(work_dir/script_name, \"w\") as f:\n",
    "        f.write(job_script)\n",
    "    process = run_slurm_job(work_dir, executor=\"sbatch\", script_name=script_name)\n",
    "    ## get the output of the job\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == b'' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.decode().strip())\n",
    "    print(f\"Submitted job {job_name} with PID {process.pid}\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./CGCNN_MT/data/WS24v2_external_test/cifs\n",
      "46 46\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "cif_dirs = [\n",
    "    # \"./CGCNN_MT/data/TS_external_test/cifs\",\n",
    "    \"./CGCNN_MT/data/WS24v2_external_test/cifs\"\n",
    "]\n",
    "\n",
    "for cif_dir in cif_dirs:\n",
    "    output_dir = Path(cif_dir).parent / \"clean_cifs\"\n",
    "    print(cif_dir)\n",
    "    print(len(list(Path(cif_dir).glob(\"*.cif\"))), len(list(output_dir.glob(\"*.cif\"))))\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare graph data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 199523\n",
      "Submitted job prepare_WS24v2_external_test with PID 2562377\n"
     ]
    }
   ],
   "source": [
    "job_templet = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --output={log_dir}/%x_%A.out\n",
    "#SBATCH --error={log_dir}/%x_%A.err\n",
    "#SBATCH --partition=C9654 \n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task={n_cpus}\n",
    "#SBATCH --mem-per-cpu=50G\n",
    "\n",
    "export PATH=/opt/share/miniconda3/envs/mofmthnn/bin/:$PATH\n",
    "export LD_LIBRARY_PATH=/opt/share/miniconda3/envs/mofmthnn/lib/:$LD_LIBRARY_PATH\n",
    "\n",
    "srun python -u prepare_data.py --cif_dir {cif_dir} --n_cpus {n_cpus}\n",
    "\"\"\".strip()\n",
    "\n",
    "\n",
    "script_name = \"prepare.sh\"\n",
    "work_dir = Path(\"./CGCNN_MT/datamodule\")\n",
    "\n",
    "cif_dirs = [\n",
    "    # \"./CGCNN_MT/data/TS_external_test/clean_cifs\",\n",
    "    \"./CGCNN_MT/data/WS24v2_external_test/clean_cifs\"\n",
    "]\n",
    "\n",
    "for cif_dir in cif_dirs:\n",
    "    job_name = f\"prepare_{Path(cif_dir).parent.name}\"\n",
    "    log_dir = Path(cif_dir).parent\n",
    "    n_cpus = 1\n",
    "    job_script = job_templet.format(job_name=job_name, \n",
    "                                            cif_dir=cif_dir, \n",
    "                                            log_dir=log_dir, \n",
    "                                            n_cpus=n_cpus\n",
    "                                            )\n",
    "    with open(work_dir/script_name, \"w\") as f:\n",
    "        f.write(job_script)\n",
    "    process = run_slurm_job(work_dir, executor=\"sbatch\", script_name=script_name)\n",
    "    ## get the output of the job\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == b'' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.decode().strip())\n",
    "    print(f\"Submitted job {job_name} with PID {process.pid}\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare zeo++ and RACs feature files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 199524\n",
      "Submitted job cif_feat_WS24v2_external_test with PID 2562727\n"
     ]
    }
   ],
   "source": [
    "job_templet_feat = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --output={log_dir}/%x_%A.out\n",
    "#SBATCH --error={log_dir}/%x_%A.err\n",
    "#SBATCH --partition=C9654 \n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=96\n",
    "export PATH=/opt/share/miniconda3/envs/mofmthnn/bin/:$PATH\n",
    "export LD_LIBRARY_PATH=/opt/share/miniconda3/envs/mofmthnn/lib/:$LD_LIBRARY_PATH\n",
    "\n",
    "srun python -u feature_generation.py --cif_dir {cif_dir} --prob_radius {prob_radius}\n",
    "\"\"\"\n",
    "\n",
    "work_dir = Path(\"./ML/featuring\")\n",
    "data_dir = Path(\"./CGCNN_MT/data\")\n",
    "task_names = [\n",
    "    # \"TS_external_test\", \n",
    "    \"WS24v2_external_test\"\n",
    "    ]\n",
    "script_name = \"run_slurm.sh\"\n",
    "\n",
    "for task_name in task_names:\n",
    "    job_name = f\"cif_feat_{task_name}\"\n",
    "    cif_dir = data_dir/f\"{task_name}/clean_cifs\"\n",
    "    prob_radius = 1.86\n",
    "    job_script = job_templet_feat.format(job_name=job_name, \n",
    "                                    cif_dir=cif_dir, \n",
    "                                    prob_radius=prob_radius, \n",
    "                                    log_dir=cif_dir.parent\n",
    "                                    )\n",
    "    with open(work_dir/script_name, \"w\") as f:\n",
    "        f.write(job_script)\n",
    "    process = run_slurm_job(work_dir, executor=\"sbatch\", script_name=script_name)\n",
    "    while True:\n",
    "        output = process.stdout.readline()\n",
    "        if output == b'' and process.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.decode().strip())\n",
    "    print(f\"Submitted job {job_name} with PID {process.pid}\")\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge zeo++ and RACs features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46, 192) (46, 9)\n",
      "(46, 197)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "## WS24_external_test\n",
    "feat_file = \"./CGCNN_MT/data/WS24v2_external_test/RAC_and_zeo_features.csv\"\n",
    "id_prop_file = \"./CGCNN_MT/data/WS24v2_external_test/id_prop.csv\"\n",
    "out_file = feat_file.replace(\".csv\", \"_with_id_prop.csv\")\n",
    "\n",
    "df_new = pd.read_csv(feat_file)\n",
    "df = pd.read_csv(id_prop_file)\n",
    "\n",
    "print(df_new.shape, df.shape)\n",
    "df_new.drop(columns=['cif_file'], inplace=True)\n",
    "df_new.rename(columns={'name': 'MofName'}, inplace=True)\n",
    "\n",
    "id_prop_cols = [\"MofName\", \"Partition\", \"water_label\", \"water4_label\", \"acid_label\", \"base_label\", \"boiling_label\"]\n",
    "df_new = df[id_prop_cols].merge(df_new, on=\"MofName\", how=\"left\")\n",
    "# df_new.dropna(axis=0, how='any', inplace=True)\n",
    "print(df_new.shape)\n",
    "df_new.to_csv(out_file, index=False)\n",
    "\n",
    "\n",
    "# TS_external_test\n",
    "feat_file = \"./CGCNN_MT/data/TS_external_test/RAC_and_zeo_features.csv\"\n",
    "id_prop_file = \"./CGCNN_MT/data/TS_external_test/id_prop.csv\"\n",
    "out_file = feat_file.replace(\".csv\", \"_with_id_prop.csv\")\n",
    "\n",
    "df_new = pd.read_csv(feat_file)\n",
    "df = pd.read_csv(id_prop_file)\n",
    "\n",
    "print(df_new.shape, df.shape)\n",
    "df_new.drop(columns=['cif_file'], inplace=True)\n",
    "df_new.rename(columns={'name': 'MofName'}, inplace=True)\n",
    "\n",
    "df[\"ts2_label\"] = (df[\"ts_label\"] >= 359).astype(int)\n",
    "id_prop_cols = [\"MofName\", \"Partition\", \"ts_label\", \"ts2_label\", \"ss_label\"]\n",
    "df_new = df[id_prop_cols].merge(df_new, on=\"MofName\", how=\"left\")\n",
    "df_new.dropna(axis=0, how='any', inplace=True)\n",
    "print(df_new.shape)\n",
    "df_new.to_csv(out_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mofmthnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
