{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (DatabaseError('database disk image is malformed')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from pathlib import Path\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_templet = \"\"\"#!/bin/bash\n",
    "#SBATCH --job-name={job_name}\n",
    "#SBATCH --output=slurm_logs/%x_%A.out\n",
    "#SBATCH --error=slurm_logs/%x_%A.err\n",
    "#SBATCH --partition=C9654\n",
    "#SBATCH --nodelist=c3\n",
    "#SBATCH --ntasks-per-node=1\n",
    "#SBATCH --cpus-per-task=64\n",
    "#SBATCH --mem-per-gpu=100G\n",
    "#SBATCH --gres=gpu:1\n",
    "export PATH=/opt/share/miniconda3/envs/mofmthnn/bin/:$PATH\n",
    "export LD_LIBRARY_PATH=/opt/share/miniconda3/envs/mofmthnn/lib/:$LD_LIBRARY_PATH\n",
    "\n",
    "srun python -u {py_executor} --progress_bar --task_cfg {task_config} --model_cfg {model_config}\n",
    "\"\"\".strip()\n",
    "\n",
    "def run_slurm_job(work_dir, executor=\"sbatch\", script_name=\"run\"):\n",
    "    work_dir = Path(work_dir)\n",
    "    # Create a script to run the job\n",
    "    process = subprocess.Popen(\n",
    "        f\"{executor} {work_dir/script_name}\",\n",
    "        # [executor, str(work_dir/'run'), \"&\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        stderr=subprocess.PIPE,\n",
    "        shell=True,\n",
    "        env=os.environ.copy(),\n",
    "        cwd=str(work_dir)\n",
    "    )\n",
    "    return process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training original CGCNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted batch job 199555\n",
      "Submitted job opt_tsd_ssd_ws24_cgcnn_raw with PID 1736896\n"
     ]
    }
   ],
   "source": [
    "work_dir = Path(\"./CGCNN_MT\").absolute()\n",
    "\n",
    "task_configs = [\n",
    "    # \"tsd_ssd\",\n",
    "    \"tsd_ssd_ws24\",\n",
    "    # \"tsd_ssd_ws24_water\",\n",
    "    # \"tsd_ssd_ws24_water_water4\",\n",
    "    # \"tsd_ssd_ws24_water\",\n",
    "    # \"ssd_ws24\",\n",
    "    # \"ws24\",\n",
    "    # \"tsd\",\n",
    "    # \"ssd\",\n",
    "    # \"ws24_water\",\n",
    "    # \"ws24_water4\",\n",
    "    # \"ws24_acid\",\n",
    "    # \"ws24_base\",\n",
    "    # \"ws24_boiling\"\n",
    "                    ]\n",
    "model_configs = [\n",
    "    # \"att_cgcnn\",\n",
    "    # \"cgcnn\",\n",
    "    \"cgcnn_raw\",\n",
    "    # \"fcnn\",\n",
    "    # \"att_fcnn\",\n",
    "    # \"cgcnn_uni_atom\"\n",
    "]\n",
    "script_name = \"run_slurm.sh\"\n",
    "py_executor = \"hyperopt.py\"\n",
    "# py_executor = \"main.py\"\n",
    "model_conf = {\n",
    "            'batch_size': 32,\n",
    "            'max_epochs': 500, \n",
    "            'max_graph_len': 200,\n",
    "            'atom_fea_len': 256,\n",
    "            'extra_fea_len': 16,\n",
    "            'h_fea_len': 128,\n",
    "            'n_conv': 6,\n",
    "            'n_h': 4,\n",
    "            'dropout_prob': 0.5,\n",
    "            'use_extra_fea': False,\n",
    "            'use_cell_params': False,\n",
    "            'atom_layer_norm': False,\n",
    "            'loss_aggregation': \"fixed_weight_sum\",   # fixed_weight_sum, dwa, sum, sample_weight_sum, trainable_weight_sum\n",
    "            'dl_sampler': 'random',\n",
    "            'task_att_type': 'none',\n",
    "            'augment': False,\n",
    "            'lr': 0.001,\n",
    "            'lr_mult': 10,\n",
    "            'group_lr': False,\n",
    "            'optim_config': \"fine\",  # fine or coarse\n",
    "            'auto_lr_bs_find': False, \n",
    "            'patience': 50,\n",
    "            'task_norm': False,\n",
    "            'log_dir': \"logs\",\n",
    "            'optuna_name': \"optuna\",\n",
    "            }\n",
    "\n",
    "for task_config in task_configs:\n",
    "    for model_config in model_configs:\n",
    "        job_name = f\"{task_config.replace('_config', '')}_{model_config.replace('_config', '')}\"\n",
    "        if py_executor == \"hyperopt.py\":\n",
    "            job_name = \"opt_\" + job_name\n",
    "            # job_templet_ = job_templet + \" --pruning\"\n",
    "            job_templet_ = job_templet\n",
    "        else:\n",
    "            job_templet_ = job_templet\n",
    "        job_script = job_templet_.format(job_name=job_name, \n",
    "                                        task_config=task_config, \n",
    "                                        model_config=model_config,\n",
    "                                        py_executor=py_executor\n",
    "                                        )\n",
    "        \n",
    "        for key, value in model_conf.items():\n",
    "            if isinstance(value, bool):\n",
    "                if value:\n",
    "                    job_script += f\" --{key}\"\n",
    "                continue\n",
    "            job_script += f\" --{key} {value}\"\n",
    "        with open(work_dir/script_name, \"w\") as f:\n",
    "            f.write(job_script)\n",
    "        process = run_slurm_job(work_dir, executor=\"sbatch\", script_name=script_name)\n",
    "        ## get the output of the job\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == b'' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.decode().strip())\n",
    "        print(f\"Submitted job {job_name} with PID {process.pid}\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training refined CGCNN model (MOFSNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir = Path(\"./CGCNN_MT\")\n",
    "\n",
    "task_configs = [\n",
    "    # \"tsd_ssd\",\n",
    "    \"tsd_ssd_ws24\",\n",
    "    # \"tsd_ssd_ws24_water\",\n",
    "    # \"tsd_ssd_ws24_water_water4\",\n",
    "    # \"tsd_ssd_ws24_water\",\n",
    "    # \"ssd_ws24\",\n",
    "    # \"ws24\",\n",
    "    \"tsd\",\n",
    "    \"ssd\",\n",
    "    \"ws24_water\",\n",
    "    \"ws24_water4\",\n",
    "    \"ws24_acid\",\n",
    "    \"ws24_base\",\n",
    "    \"ws24_boiling\"\n",
    "                    ]\n",
    "model_configs = [\n",
    "    \"att_cgcnn\",\n",
    "    # \"cgcnn\",\n",
    "    # \"cgcnn_raw\",\n",
    "    # \"fcnn\",\n",
    "    # \"att_fcnn\",\n",
    "    # \"cgcnn_uni_atom\"\n",
    "]\n",
    "script_name = \"run_slurm.sh\"\n",
    "py_executor = \"hyperopt.py\"\n",
    "# py_executor = \"main.py\"\n",
    "model_conf = {\n",
    "            'batch_size': 32,\n",
    "            'max_epochs': 500, \n",
    "            'max_graph_len': 200,\n",
    "            'atom_fea_len': 256,\n",
    "            'extra_fea_len': 16,\n",
    "            'h_fea_len': 128,\n",
    "            'n_conv': 6,\n",
    "            'n_h': 4,\n",
    "            'dropout_prob': 0.5,\n",
    "            'use_extra_fea': False,\n",
    "            'use_cell_params': True,\n",
    "            'atom_layer_norm': True,\n",
    "            'loss_aggregation': \"fixed_weight_sum\",   # fixed_weight_sum, dwa, sum, sample_weight_sum, trainable_weight_sum\n",
    "            'dl_sampler': 'random',\n",
    "            'task_att_type': 'self',\n",
    "            'augment': False,\n",
    "            'lr': 0.001,\n",
    "            'lr_mult': 10,\n",
    "            'group_lr': True,\n",
    "            'optim_config': \"fine\",  # fine or coarse\n",
    "            'auto_lr_bs_find': False, \n",
    "            'patience': 50,\n",
    "            'task_norm': True,\n",
    "            'log_dir': \"logs\",\n",
    "            'optuna_name': \"optuna\",\n",
    "            }\n",
    "\n",
    "for task_config in task_configs:\n",
    "    for model_config in model_configs:\n",
    "        job_name = f\"{task_config.replace('_config', '')}_{model_config.replace('_config', '')}\"\n",
    "        if py_executor == \"hyperopt.py\":\n",
    "            job_name = \"opt_\" + job_name\n",
    "            # job_templet_ = job_templet + \" --pruning\"\n",
    "            job_templet_ = job_templet\n",
    "        else:\n",
    "            job_templet_ = job_templet\n",
    "        job_script = job_templet_.format(job_name=job_name, \n",
    "                                        task_config=task_config, \n",
    "                                        model_config=model_config,\n",
    "                                        py_executor=py_executor\n",
    "                                        )\n",
    "        \n",
    "        for key, value in model_conf.items():\n",
    "            if isinstance(value, bool):\n",
    "                if value:\n",
    "                    job_script += f\" --{key}\"\n",
    "                continue\n",
    "            job_script += f\" --{key} {value}\"\n",
    "        with open(work_dir/script_name, \"w\") as f:\n",
    "            f.write(job_script)\n",
    "        process = run_slurm_job(work_dir, executor=\"sbatch\", script_name=script_name)\n",
    "        ## get the output of the job\n",
    "        while True:\n",
    "            output = process.stdout.readline()\n",
    "            if output == b'' and process.poll() is not None:\n",
    "                break\n",
    "            if output:\n",
    "                print(output.decode().strip())\n",
    "        print(f\"Submitted job {job_name} with PID {process.pid}\")\n",
    "        time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mofmthnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
